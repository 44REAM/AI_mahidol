{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNF6NSyWODgWZqWnF+B8TEX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/44REAM/AI_mahidol/blob/master/week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "726j-m81wRyh",
        "colab_type": "text"
      },
      "source": [
        "# Latent variable\n",
        "\n",
        "Latent variables are variable that you not directly observed. But sometime we can construct that variables from physical reality.\n",
        "\n",
        "For example\n",
        "\n",
        "1. In advertising\n",
        "\n",
        "You can collect data of person (e.g. ages, sex, what product they like to buy) and use their data to predict what they want to buy. But you cannot record their emotion and emotion may effect the decision whether they want to buy the product. And emotion is your latent variable.\n",
        "\n",
        "2. iuyiuyi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaX3AXGQwW3K",
        "colab_type": "text"
      },
      "source": [
        "# GMM (Gaussian mixture model)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1gjilUVmv2H0mL4f9ZdrFEFpKivuUEjQr)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1sfuaeJpyziHQbhIIBu38TzqwGggjzITY)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Q_AQJtgGlK0nMEhbK67aELSHGhQE39ar)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1MqIULg0zfezXSioGl84JfTOmblfDlTwS)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Fe0VJt2jULPruSUxt3wuTRyDFuj8t23C)\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1Z4lRg2J9g-cWvGOBmGuYjEPRf1Xi7jbN)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy-wwKpe6swf",
        "colab_type": "text"
      },
      "source": [
        "We can build graphical model like this\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1KCKPSvL3fOLPvLF7sxLE8RlwLEy1VYHg)\n",
        "\n",
        "Let \n",
        "\n",
        "> $z \\thicksim Categorical(\\pi)$\n",
        "\n",
        "> $k$ = number of category\n",
        "\n",
        "\n",
        "\n",
        "$$p(x) = \\sum_{all \\ z} p(x,Z)$$\n",
        "\n",
        "$$p(x) = \\sum_{all \\ z} p(Z)p(x \\mid Z)$$\n",
        "\n",
        "define\n",
        "\n",
        "> $p(z = k) = \\pi_k$\n",
        "\n",
        "we can model $p(x \\mid z = k)$ as gaussian\n",
        "\n",
        "$$p(x \\mid z = k) = \\mathcal{N}(x \\mid \\mu_k, \\sigma_k)$$\n",
        "\n",
        "you got \n",
        "\n",
        "$$p(x) = \\sum_{k} \\pi_k \\mathcal{N}(x \\mid \\mu_k, \\sigma_k)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1ooJLGNLHIJ",
        "colab_type": "text"
      },
      "source": [
        "We want   $p(z = k \\mid x)$\n",
        "\n",
        "$$p(z = k \\mid x) = \\frac{p(z=k,x)}{p(x)}$$\n",
        "\n",
        "\n",
        "\n",
        "$$p(z = k \\mid x) = \\frac{\\pi_k \\mathcal{N}(x \\mid \\mu_k, \\sigma_k)}{\\sum_{k} \\pi_k \\mathcal{N}(x \\mid \\mu_k, \\sigma_k)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViQpszrQbp0V",
        "colab_type": "text"
      },
      "source": [
        "# PCA (Principal component analysis)\n",
        "\n",
        "If you have many variable (feature) in your data,sometime you may want to reduced the variable (feature) that insert into your model. In otherword you may want to reduce the dimension of your feature space but still preserved the information of your data.\n",
        "\n",
        "## Normal approach\n",
        "\n",
        "*   $w$ is unit vector parallel to the axis that have most variance\n",
        "*   X is two dimension matrix $m \\times n$ for $m$ is number of dataset and $n$ is number of feature\n",
        "\n",
        "You want to maximum the variance of $Xw$ subject to $w$ is unit vector\n",
        "\n",
        "> Maximum $||Xw||^2$ \\\n",
        "> Subject to  $||w||^2 = 1$\n",
        "\n",
        "You can construct lagrange function $\\mathcal{L}$\n",
        "\n",
        "$$\\mathcal{L}(X,w,\\lambda) = ||Xw||^2 - \\lambda||w||^2$$\n",
        "\n",
        "> for $\\lambda$ is lagrange constant\n",
        "\n",
        "you want to find $w$ so just differentiate with w.\n",
        "\n",
        "$$\\frac{ \\partial ||Xw||^2}{\\partial w} = \\lambda \\frac{\\partial{||w||^2}}{\\partial w}$$\n",
        "\n",
        "$$ X^TXw = C w$$ for $C$ is some constant\n",
        "\n",
        "Went you look to the equation it may remind you of something. It is eigenvector/eigenvalue equation.\n",
        "\n",
        "Let $A = X^TX$\n",
        "\n",
        "$$ Aw = Cw$$\n",
        "\n",
        "or \n",
        "\n",
        "$$A = V \\Lambda V^{-1}$$\n",
        "\n",
        "> $V$ is eigenvector matrix \\\n",
        "> $\\Lambda$ is eigenvalue matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuo6iRvhwRBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "$p(x \\mid z) = $"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}